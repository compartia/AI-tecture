{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM5CBWAAkXt9+cg441wKHMO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/compartia/AI-tecture/blob/master/miro_openai_pipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Miro and Chat GPT\n",
        "\n",
        " status: **DRAFT**\n",
        "\n",
        " **by:** Artem Zaborskiy\n",
        "\n",
        "\n",
        " system that integrates AI-generated content with Miro (https://miro.com/), a collaborative online whiteboard platform. It specifically handles the part of the workflow where an AI-generated response is posted back to the Miro board, enhancing the interactive and dynamic capabilities of the board by incorporating AI insights directly into the collaborative workspace.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "0TD4KZgQRolG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODOs:\n",
        "\n",
        "1. sort nodes to process, proritize, what propmps to process first\n",
        "1. cache processing results,\n",
        "1. ~~check dates or checksums~~\n",
        "1. check for self-connected nodes\n",
        "1. check for prompt-prompt connectors\n",
        "1. do not reload the entire board after widget created: add new widget and its connector to dataframes\n",
        "1. ~~create output shape if propmpt node has no output connectors~~"
      ],
      "metadata": {
        "id": "wZF7wgCUo_60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare OPEN AI client"
      ],
      "metadata": {
        "id": "mgh_Yl64GmYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML"
      ],
      "metadata": {
        "id": "DFDb4tbHI-Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai typing-extensions"
      ],
      "metadata": {
        "id": "mdlRmobQRvU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "ai_client = openai.OpenAI(api_key=userdata.get('OP_API')  )"
      ],
      "metadata": {
        "id": "dKAaHFKTRveu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOARD_ID = 'uXjVN61x8Pg='\n",
        "DEBUG_OPENAI = False"
      ],
      "metadata": {
        "id": "yWPQ26qRlSI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test open AI api calls"
      ],
      "metadata": {
        "id": "pdmuX6DrGCTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "if DEBUG_OPENAI:\n",
        "  completion = ai_client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair. Your answer is in a form of list of <p> html tags.\"},\n",
        "      {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  # print(completion.choices[0].message)\n",
        "  display(HTML(completion.choices[0].message.content))"
      ],
      "metadata": {
        "id": "sByeqew3Gi9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "if DEBUG_OPENAI:\n",
        "  completion = ai_client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair. Your answer is in a form of list of <p> html tags.\"},\n",
        "      {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "    ]\n",
        "  )\n",
        "  #\n",
        "  # print(completion.choices[0].message)\n",
        "  display(HTML(completion.choices[0].message.content))"
      ],
      "metadata": {
        "id": "G4igP8-uGx-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "if DEBUG_OPENAI:\n",
        "  completion = ai_client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair. Your answer is in a form of list of <p> html tags.\"},\n",
        "      {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  display(HTML(completion.choices[0].message.content))"
      ],
      "metadata": {
        "id": "gyGRd7BKHAXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API tools"
      ],
      "metadata": {
        "id": "N5aZVT3Ykouu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_ai(prompt, argument_context):\n",
        "\n",
        "  completion = ai_client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": f\"{prompt}. Your answer is in a form of list of <p> HTML tags and has NO newline '\\n' symbols.\"},\n",
        "      {\"role\": \"user\", \"content\": argument_context}\n",
        "    ]\n",
        "  )\n",
        "  print(completion.choices)\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "if DEBUG_OPENAI or True:\n",
        "  r = ask_ai('you are a female philosopher. Answer in 2 words.', 'what is the meaning of life?')\n",
        "  print(r)\n",
        "  display(HTML(r))\n",
        "  # display(HTML(r))"
      ],
      "metadata": {
        "id": "PRjlYd75JPHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if DEBUG_OPENAI or True:\n",
        "  r = ask_ai('you are a male philosopher. Answer in 2 words.', 'what is the meaning of life?')\n",
        "  print(r)\n",
        "  display(HTML(r))\n",
        "  # display(HTML(r))"
      ],
      "metadata": {
        "id": "eWcC9jNJTsws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Miro client\n",
        "https://developers.miro.com/reference/api-reference"
      ],
      "metadata": {
        "id": "MgnF85-Pk3Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class MiroClient:\n",
        "  def __init__(self, token, board_id):\n",
        "    self.board_id = board_id\n",
        "    self.token = token\n",
        "    self.base_url = f\"https://api.miro.com/v2/boards/{board_id}\"\n",
        "\n",
        "    self.headers = {\n",
        "        \"accept\": \"application/json\",\n",
        "        \"authorization\": f\"Bearer {self.token}\"\n",
        "    }\n",
        "\n",
        "\n",
        "  def get_items(self, cursor=None, limit=50):\n",
        "    limit_p = f'limit={limit}'\n",
        "\n",
        "    url = f\"{self.base_url}/items?{limit_p}\"\n",
        "    if cursor is not None:\n",
        "      url = f\"{self.base_url}/items?cursor={cursor}&{limit_p}\"\n",
        "\n",
        "    response = requests.get(url, headers=self.headers)\n",
        "    return response\n",
        "\n",
        "  def get_connectors(self, cursor=None, limit=50):\n",
        "    limit_p = f'limit={limit}'\n",
        "\n",
        "    url = f\"{self.base_url}/connectors?{limit_p}\"\n",
        "    if cursor is not None:\n",
        "      url = f\"{self.base_url}/connectors?cursor={cursor}&{limit_p}\"\n",
        "\n",
        "    response = requests.get(url, headers=self.headers)\n",
        "    return response\n",
        "\n",
        "\n",
        "  def get_all_pages(self, page_method):\n",
        "\n",
        "    cursor = None\n",
        "\n",
        "    max_steps = 30\n",
        "    step = 0\n",
        "    while True:\n",
        "      step += 1\n",
        "      response = page_method(cursor)\n",
        "      rj = response.json()\n",
        "      yield rj\n",
        "      cursor = rj.get('cursor')\n",
        "      if cursor is None or step > max_steps:\n",
        "        break\n",
        "\n",
        "\n",
        "miro_client = MiroClient(userdata.get('MIRO_TOOKEN'), BOARD_ID)\n"
      ],
      "metadata": {
        "id": "Z99dNYc8jOA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting all connectors"
      ],
      "metadata": {
        "id": "rXIxqwkx1RMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_connectors(page:dict):\n",
        "  # print(page)\n",
        "  for i in page['data']:\n",
        "    yield i['id'], i.get('startItem', {}).get('id'), i.get('endItem', {}).get('id')\n",
        "\n",
        "\n",
        "##-----\n",
        "## test it\n",
        "one_page_con = miro_client.get_connectors(limit=10).json()\n",
        "x = [i for i in decode_connectors(one_page_con)]\n",
        "x"
      ],
      "metadata": {
        "id": "_PBOp6pZwCau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_connectors(self):\n",
        "  for page in self.get_all_pages(self.get_connectors):\n",
        "    for i in decode_connectors(page):\n",
        "      yield i\n",
        "\n",
        "\n",
        "def all_connectors_as_df(miro_client):\n",
        "  all_connectors_iter = miro_client.get_all_connectors()\n",
        "  miro_client.connectors_df = pd.DataFrame(all_connectors_iter, columns=['id','id_from', 'id_to'])\n",
        "  miro_client.connectors_df = miro_client.connectors_df.set_index('id')\n",
        "\n",
        "\n",
        "  return miro_client.connectors_df\n",
        "\n",
        "\n",
        "MiroClient.get_all_connectors = get_all_connectors\n",
        "MiroClient.all_connectors_as_df = all_connectors_as_df\n",
        "\n",
        "\n",
        "\n",
        "##-----\n",
        "miro_client = MiroClient(userdata.get('MIRO_TOOKEN'), BOARD_ID)\n",
        "\n",
        "connectors_df = miro_client.all_connectors_as_df()\n",
        "connectors_df\n"
      ],
      "metadata": {
        "id": "KQqR-FymxOHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting all shapes (widgets)"
      ],
      "metadata": {
        "id": "ChwakwI91NJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_items(page:dict):\n",
        "\n",
        "  for i in page['data']:\n",
        "    # print(type(i))\n",
        "    if type(i) == dict :\n",
        "      yield i['id'], i['type'], i['data'].get('shape', '_undefined_'), i['data'].get('content'), i['modifiedAt'], i['geometry'], i['position']\n",
        "\n",
        "    else:\n",
        "      print('NOT A DICT!!', type(i), i)\n",
        "      decode_items(i)\n",
        "\n",
        "\n",
        "\n",
        "def get_all_items(self):\n",
        "  for page in self.get_all_pages(self.get_items):\n",
        "    # print( page.get('cursor'), page.get('size'), page.get('total') )\n",
        "    for i in decode_items(page):\n",
        "      yield i\n",
        "      # print(i)\n",
        "\n",
        "\n",
        "MiroClient.get_all_items = get_all_items"
      ],
      "metadata": {
        "id": "KK69YBMzWrmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def all_items_as_df(miro_client):\n",
        "  items_iter = miro_client.get_all_items()\n",
        "\n",
        "  df = pd.DataFrame(items_iter, columns=['id','type', 'shape', \"contents\", 'modifiedAt', 'geometry', 'position'])\n",
        "  df = df.set_index('id')\n",
        "  df['modifiedAt_date'] = pd.to_datetime(df['modifiedAt'])\n",
        "\n",
        "  miro_client.shapes_df = df\n",
        "  return miro_client.shapes_df\n",
        "\n",
        "\n",
        "MiroClient.all_items_as_df = all_items_as_df\n",
        "# --------\n",
        "\n",
        "miro_client = MiroClient(userdata.get('MIRO_TOOKEN'), BOARD_ID)\n",
        "shapes_df = miro_client.all_items_as_df()"
      ],
      "metadata": {
        "id": "PL9z0V2WMs5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shapes_df"
      ],
      "metadata": {
        "id": "e9b4QVNkRXhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update board item"
      ],
      "metadata": {
        "id": "D2dKqEeDLfjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_shape_info(self, shape_id):\n",
        "  url = f\"{self.base_url}/shapes/{shape_id}\"\n",
        "  response = requests.get(url, headers=self.headers)\n",
        "  print(response.text)\n",
        "\n",
        "def get_stiky_note_info(self, shape_id):\n",
        "  url = f\"{self.base_url}/sticky_notes/{shape_id}\"\n",
        "  response = requests.get(url, headers=self.headers)\n",
        "  print(response.text)\n",
        "\n",
        "\n",
        "def update_item(self, shape_id, item_type, content, shape=None, color = None):\n",
        "\n",
        "  url = None\n",
        "\n",
        "  payload = {\n",
        "      \"data\": {\n",
        "          \"content\": content\n",
        "      }\n",
        "  }\n",
        "\n",
        "\n",
        "  if color is not None:\n",
        "    payload['style']={}\n",
        "    payload['style']['fillColor'] = color\n",
        "\n",
        "    if item_type!='sticky_note':\n",
        "      payload['style']['fillOpacity'] = \"1.0\"\n",
        "\n",
        "\n",
        "  if item_type=='sticky_note':\n",
        "    url = f\"{self.base_url}/sticky_notes/{shape_id}\"\n",
        "  elif item_type=='shape':\n",
        "    url = f\"{self.base_url}/shapes/{shape_id}\"\n",
        "    if shape is not None:\n",
        "      payload['data']['shape'] = shape\n",
        "\n",
        "  print(payload)\n",
        "\n",
        "\n",
        "  response = requests.patch(url, json=payload, headers=self.headers)\n",
        "  print(response.text)\n",
        "  return response\n",
        "\n",
        "\n",
        "\n",
        "MiroClient.update_item = update_item\n",
        "MiroClient.get_shape_info = get_shape_info\n",
        "MiroClient.get_stiky_note_info = get_stiky_note_info\n",
        "\n",
        "#-----\n",
        "\n",
        "miro_client = MiroClient(userdata.get('MIRO_TOOKEN'), BOARD_ID)\n",
        "\n",
        "# if False:\n",
        "\n",
        "  # miro_client.get_stiky_note_info('3458764578213963472')\n",
        "# test_id = '3458764578216605194'\n",
        "# miro_client.update_item( test_id, item_type=shapes_df.at[test_id, 'type'], content=completion.choices[0].message.content,  color='#ff0000')"
      ],
      "metadata": {
        "id": "PLj1AZXaLdTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_connector(self, form, to, text):\n",
        "  import requests\n",
        "\n",
        "  url = f\"{self.base_url}/connectors\"\n",
        "\n",
        "  payload = {\n",
        "      \"startItem\": {\n",
        "          \"id\": form,\n",
        "          \"snapTo\": \"right\"\n",
        "      },\n",
        "      \"endItem\": {\n",
        "          \"id\": to,\n",
        "          \"snapTo\": \"auto\"\n",
        "      },\n",
        "      \"style\": { \"endStrokeCap\": \"arrow\" },\n",
        "      \"shape\": \"curved\",\n",
        "      \"captions\": [{ \"content\": text }]\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=self.headers)\n",
        "  return response\n",
        "\n",
        "\n",
        "def create_stiky_note(self, contents, pos):\n",
        "\n",
        "  url = f\"{self.base_url}/sticky_notes\"\n",
        "\n",
        "  payload = {\n",
        "    \"data\": {\n",
        "        \"content\": contents,\n",
        "        \"shape\": \"rectangle\"\n",
        "    },\n",
        "    \"style\": {\n",
        "        \"fillColor\": \"pink\",\n",
        "        \"textAlign\": \"left\"\n",
        "    },\n",
        "    \"position\": {\n",
        "        \"x\": pos[0],\n",
        "        \"y\": pos[1]\n",
        "    },\n",
        "    \"geometry\": {\n",
        "        \"height\": pos[2]\n",
        "        # \"width\": pos[3]\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=self.headers)\n",
        "  return response\n",
        "\n",
        "\n",
        "MiroClient.create_stiky_note = create_stiky_note\n",
        "MiroClient.create_connector = create_connector\n",
        "\n",
        "\n",
        "# --------\n",
        "miro_client = MiroClient(userdata.get('MIRO_TOOKEN'), BOARD_ID)\n",
        "# response = miro_client.create_stiky_note( \"TESTCREATE\", (20,20,400,400) )\n",
        "# response.json()['id']"
      ],
      "metadata": {
        "id": "6KA8i3wcJBAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing the board\n"
      ],
      "metadata": {
        "id": "7fl6403nMD0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "miro_client = MiroClient(userdata.get('MIRO_TOOKEN'), BOARD_ID)"
      ],
      "metadata": {
        "id": "-ErmYjwsmYXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get shapes with prompts"
      ],
      "metadata": {
        "id": "oiG-BLkj4bh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_df = shapes_df[shapes_df['shape']=='parallelogram']\n",
        "prompts_df"
      ],
      "metadata": {
        "id": "PVVnxy9CWYf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find connectors of prompts-shapes (connectors of prallelograms)\n",
        "\n",
        "Updating Miro board widgets with an answers generated by an AI model. Here's a breakdown of its functionality:\n",
        "\n",
        "1. **Identify Output Links**: Finding output links of the prompt widget from the `connectors_df` DataFrame where the `id_from` matches the `prompt_id`. If no outgoing connectors are found it creates a widget on the board and links it to the propt widsget\n",
        "\n",
        "2. **Update Widget**:  the target widget(s) is updated with AI-generated answer. This update is performed by calling the `update_item` method of the `miro_client` object\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "5YQuk-7U4iqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_output_shape(shape_id, contents = 'Waiting for AI to answer'):\n",
        "\n",
        "  global shapes_df\n",
        "\n",
        "  shape = shapes_df.loc [ shape_id ]\n",
        "\n",
        "  pos = shape['position']\n",
        "  geo = shape['geometry']\n",
        "\n",
        "  size = max(geo['width'], geo['height'])\n",
        "\n",
        "  response = miro_client.create_stiky_note( contents, (pos['x'] +  geo['width'] + size, pos['y'], size, size) )\n",
        "  a_id = response.json()['id']\n",
        "\n",
        "  response = miro_client.create_connector( shape_id,  a_id, 'AI answer' )\n",
        "\n",
        "  #TODO: OPTIMIZE!!\n",
        "  shapes_df = miro_client.all_items_as_df()\n",
        "\n",
        "  return a_id\n",
        "\n",
        "# test------\n",
        "# build_output_shape('3458764578079690837', \"TESTCREATE\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "W-fQUh3xw_kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output_shape_id(prompt_id):\n",
        "  out_links = connectors_df[ connectors_df['id_from']==prompt_id]\n",
        "  if len(out_links) > 0:\n",
        "    _items = shapes_df.loc [ out_links['id_to'] ]\n",
        "    return _items.iloc[0].name"
      ],
      "metadata": {
        "id": "-T6z4l2MN0CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_incoming_text(incoming_links):\n",
        "\n",
        "  incoming_items = shapes_df.loc [incoming_links['id_from'] ]\n",
        "  incoming_items = incoming_items.sort_values(by='position', key=lambda x: x.map(lambda d: d['y']), ascending=True)\n",
        "\n",
        "  concatenated_text = '\\n\\n'.join(incoming_items.contents)\n",
        "  # print('ii---- ',len(incoming_items), concatenated_text)\n",
        "\n",
        "  return concatenated_text"
      ],
      "metadata": {
        "id": "ALU6CKRqOLnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_incoming_max_date(incoming_links):\n",
        "  incoming_items = shapes_df.loc [incoming_links['id_from'] ]\n",
        "  return incoming_items.modifiedAt_date.max()\n",
        "\n",
        "# 3458764578299251402"
      ],
      "metadata": {
        "id": "IXWknUKGOMB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WnSTTXOzR961"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_incoming_links = connectors_df[ connectors_df['id_to']=='3458764578299251402']\n",
        "\n",
        "incoming_items = shapes_df.loc [ _incoming_links['id_from'] ]\n",
        "\n",
        "# import datetime\n",
        "print(incoming_items.modifiedAt_date.max())\n",
        "# datetime.datetime.fromisoformat(incoming_items.modifiedAt.max())"
      ],
      "metadata": {
        "id": "Lr7AGZfbOnBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_color_for_state(out_shape_id, state):\n",
        "  item_type = shapes_df.at[out_shape_id, 'type']\n",
        "\n",
        "  if state==0:\n",
        "    if item_type=='sticky_note':\n",
        "      color = 'red'\n",
        "    else:\n",
        "      color = '#ff5566'\n",
        "\n",
        "  if state==1:\n",
        "    if item_type=='sticky_note':\n",
        "      color = 'light_green'\n",
        "    else:\n",
        "      color = '#ccffdd'\n",
        "\n",
        "  return color\n",
        "\n",
        "\n",
        "def build_answer(prompt_id):\n",
        "  default_contents='waiting for AI to answer ....'\n",
        "  _propmt_text = shapes_df.loc[prompt_id]['contents']\n",
        "\n",
        "  incoming_links = connectors_df[ connectors_df['id_to']==prompt_id]\n",
        "  incoming_max_date = get_incoming_max_date(incoming_links)\n",
        "\n",
        "  # if there are more than 1 input, merge them\n",
        "  in_text = get_incoming_text(incoming_links)\n",
        "\n",
        "  update_is_required = False\n",
        "\n",
        "  out_shape_id = get_output_shape_id(prompt_id)\n",
        "  if out_shape_id is None:\n",
        "    out_shape_id = build_output_shape(prompt_id, contents =default_contents)\n",
        "    update_is_required = True\n",
        "\n",
        "  out_date = shapes_df.at[out_shape_id, 'modifiedAt_date']\n",
        "  prompt_date = shapes_df.at[prompt_id, 'modifiedAt_date']\n",
        "\n",
        "  update_is_required = (out_date < incoming_max_date) or (prompt_date > out_date) or update_is_required\n",
        "\n",
        "  if update_is_required:\n",
        "    item_type = shapes_df.at[out_shape_id, 'type']\n",
        "    color = get_color_for_state(out_shape_id, 0)\n",
        "    res = miro_client.update_item( out_shape_id, item_type=item_type, content=default_contents, color = color)\n",
        "\n",
        "    answer_text = ask_ai(_propmt_text, in_text)\n",
        "\n",
        "    try:\n",
        "      display(HTML(r))\n",
        "    except:\n",
        "      print('cannot render html', r)\n",
        "\n",
        "    color = get_color_for_state(out_shape_id, 1)\n",
        "    res = miro_client.update_item( out_shape_id, item_type=item_type, content=answer_text,  shape='round_rectangle', color = color)\n",
        "  else:\n",
        "    print('ignoring', prompt_id, f'because update date : {incoming_max_date} < {out_date}')\n",
        "\n",
        "  return r\n",
        "\n",
        "\n",
        "#TODO: sort propmpts first\n",
        "for prompt_id in prompts_df.index:\n",
        "  print('-'*40)\n",
        "  print(prompt_id, 'processing')\n",
        "  answer_text = build_answer(prompt_id)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Kizif0PUoNHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rR-k1i55ls2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fh2sdLJyGiWw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}